{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import traceback\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['person', 'laptop', 'chair', 'tvmonitor', 'diningtable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOV3:\n",
    "    def __init__(self, targets):\n",
    "        self.objects = {name:[] for name in targets} # {target_name:[(id, box, center)]}\n",
    "        self.target_names = targets\n",
    "        self.net, self.output_layers, self.classes, self.targets = self.load_yolo(self.target_names)\n",
    "        \n",
    "    def load_yolo(self, targets):\n",
    "        # Load Yolo\n",
    "        net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "        targets = np.array([np.where(np.array(classes) == target) for target in target_names]).flatten() # find index of wanted targets\n",
    "        #print(targets)\n",
    "        layer_names = net.getLayerNames()\n",
    "        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        \n",
    "        return net, output_layers, classes, targets\n",
    "\n",
    "    def detect_objects(self, size=(320,320), swapRB=True, crop=False, scalefactor=0.00392):\n",
    "        # Detecting objects\n",
    "        blob = cv2.dnn.blobFromImage(self.img, scalefactor, size, (0, 0, 0), swapRB, crop=crop)\n",
    "        self.net.setInput(blob)\n",
    "        outs = self.net.forward(self.output_layers)\n",
    "    \n",
    "        self.outs = outs\n",
    "    \n",
    "    # Showing informations on the screen\n",
    "    def find_indexes(self, conf=0.9):\n",
    "        self.class_ids = []\n",
    "        self.confidences = []\n",
    "        self.boxes = []\n",
    "        self.centers = []\n",
    "        dims = self.img.shape\n",
    "        for out in self.outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > conf and class_id in self.targets:\n",
    "                    # Object detected\n",
    "                    center_x = int(detection[0] * dims[1])\n",
    "                    center_y = int(detection[1] * dims[0])\n",
    "                    w = int(detection[2] * dims[1])\n",
    "                    h = int(detection[3] * dims[0])\n",
    "\n",
    "                    # Rectangle coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    self.boxes.append([x, y, w, h])\n",
    "                    self.centers.append((center_x, center_y))\n",
    "                    self.confidences.append(float(confidence))\n",
    "                    self.class_ids.append(class_id)\n",
    "\n",
    "        self.indexes = cv2.dnn.NMSBoxes(self.boxes, self.confidences, 0.5, 0.4) # non max suppression\n",
    "        \n",
    "    def find_NMS_boxes(self):\n",
    "        self.objects = {name:[] for name in self.target_names} # clear 'prev' objects\n",
    "        self.distance = []\n",
    "        tvmonitor_ids = []\n",
    "        id_set = False\n",
    "        try:\n",
    "            for i,index in enumerate(self.indexes):\n",
    "                label = str(self.classes[self.class_ids[index[0]]])\n",
    "                box = self.boxes[index[0]]\n",
    "                center = self.centers[index[0]]\n",
    "                confidence = self.confidences[index[0]]\n",
    "                if label == 'tvmonitor':\n",
    "                    if id_set:\n",
    "                        self.objects[label].append([tvmonitor_ids[i], box, center,confidence]) # {target_name:[[id, [box], (center),confidence]}\n",
    "                    else:\n",
    "                        self.objects[label].append([index[0], box, center,confidence]) # {target_name:[[id, [box], (center),confidence]}\n",
    "                        tvmonitor_ids.append(index[0])\n",
    "                else:\n",
    "                    self.objects[label].append([index[0], box, center,confidence]) # {target_name:[[id, [box], (center),confidence]}\n",
    "                \n",
    "                    \n",
    "\n",
    "\n",
    "        except KeyError:\n",
    "            print('key '+ label + 'not found')\n",
    "            \n",
    "    def midpoint(self, ptA, ptB):\n",
    "        return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "        \n",
    "    def find_distance(self, target, reference, draw=False, mindistance=70, scalefactor=2.5):\n",
    "        for trgt in self.objects[target]:\n",
    "            target_objects = self.objects[reference]\n",
    "            for ref in target_objects:\n",
    "                ecdistance = dist.euclidean(trgt[2], ref[2])/2.5  # find distance from center of each object data (index 2)\n",
    "                scaledistance = ecdistance / scalefactor\n",
    "                if scaledistance < mindistance:\n",
    "                    x=ref[1][0]\n",
    "                    y=ref[1][1]\n",
    "                    w=ref[1][2]\n",
    "                    h=ref[1][3]\n",
    "                    cv2.rectangle(self.img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                if draw:\n",
    "                    cv2.line(self.img, trgt[2], ref[2],(255, 0, 0), int(self.rect_thicc/2)+1)\n",
    "                    xA,yA = trgt[2]\n",
    "                    xB,yB = ref[2]\n",
    "                    mX,mY = self.midpoint((xA, yA), (xB, yB))\n",
    "                    cv2.putText(self.img, \"{:.1f}in\".format(scaledistance), (int(mX), int(mY - 10)), self.font, \n",
    "                                self.font_size, (255,0,0), self.font_width)\n",
    "                    \n",
    "                \n",
    "    def draw_boxes_labels(self, colors=(0,255,0), labels_to_show=['tvmonitor', 'person']):\n",
    "        self.font =cv2.FONT_HERSHEY_PLAIN\n",
    "        height, width, dim = self.img.shape\n",
    "        self.rect_thicc = int(height/140)\n",
    "        if height < 140:\n",
    "            rect_thicc = 1\n",
    "        self.find_NMS_boxes()\n",
    "        for label in self.target_names:\n",
    "            if label in labels_to_show:\n",
    "                for obj in self.objects[label]:   \n",
    "                    x, y, w, h = obj[1] # obj[1] = box\n",
    "                    self.font_size = int(height/400)+1\n",
    "                    self.font_width = int(height/300)+1\n",
    "                    lbl = label\n",
    "                    color = colors\n",
    "                    cv2.rectangle(self.img, (x, y), (x + w, y + h), color, int(self.rect_thicc))\n",
    "                    cv2.circle(self.img, obj[2], self.rect_thicc*2, (0,255,0), thickness=int(self.rect_thicc/2)+1)\n",
    "                    cv2.putText(self.img, lbl + str(obj[0]) + \" \"+\"{:.1f}\".format(obj[3]), (x, y - self.font_size), self.font, self.font_size, color, self.font_width)\n",
    "                \n",
    "                \n",
    "    def yolo_frame(self, img):\n",
    "        fx=1\n",
    "        fy=1\n",
    "        self.scalemult=fx #scale for distance\n",
    "        img = cv2.resize(img, None, fx=fx, fy=fy) # resize image\n",
    "        self.img = img\n",
    "        self.detect_objects() # find all objects\n",
    "        self.find_indexes(.7) # box object if object in targets\n",
    "        self.draw_boxes_labels() # update frame\n",
    "        self.find_distance('person', 'tvmonitor', True, 200, scalefactor=2.5*self.scalemult) #scale the distance with size\n",
    "        return img\n",
    "    \n",
    "    def yolo_video(self, filename):\n",
    "        cap=cv2.VideoCapture(filename)\n",
    "        if cap.isOpened() == False: \n",
    "            print(\"Error opening video stream or file\")\n",
    "        t1 = time.time()\n",
    "        fps = .6 # initial fps\n",
    "        try:\n",
    "            while True:\n",
    "                ret, img=cap.read()\n",
    "                frame = cv2.resize(img, (768, 432)) \n",
    "                if time.time() - t1 > 1/fps:\n",
    "                    t = time.time()\n",
    "                    img = self.yolo_frame(img)\n",
    "                    fps = 1/(time.time()-t) # find fps\n",
    "                    cv2.putText(self.img, 'FPS: {0:.2f}'.format(fps), (0,15*self.font_size), self.font, self.font_size, (255,0,0), self.font_width)\n",
    "                    #open final window\n",
    "                    cv2.imshow('Feed', img)\n",
    "                    t1 = time.time()\n",
    "            #press q to quite the window\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except:\n",
    "            #traceback.print_exc() # print errors if there are any\n",
    "            print('video or camera feed ended')\n",
    "            pass\n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lab1.png')\n",
    "YOLO = YOLOV3(target_names)\n",
    "img = YOLO.yolo_frame(img)\n",
    "#cv2.imwrite('out.jpg', img)\n",
    "plt.imshow(YOLO.yolo_frame(img))\n",
    "YOLO.yolo_video(filename='conv2B training seats.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_exec_time(func, parameter):\n",
    "    t0 = time.time()\n",
    "    func(parameter)\n",
    "    return time.time() - t0\n",
    "\n",
    "sizes = []\n",
    "times = []\n",
    "for i in range(10):\n",
    "    size = 320 + i*32\n",
    "    scalefactor= i*32*2.5\n",
    "    YOLO.find_distance('person', 'tvmonitor', True, 200, scalefactor)\n",
    "    t = find_exec_time(YOLO.detect_objects, (size,size))\n",
    "    \n",
    "    sizes.append(size)\n",
    "    times.append(t)\n",
    "    \n",
    "plt.plot(sizes, times)\n",
    "plt.title('Input Size vs. Time to Find Objects')\n",
    "plt.xlabel('Input Image Size (pixels)')\n",
    "plt.ylabel('Time(s)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
